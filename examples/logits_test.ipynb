{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "J2TwJrZ08wXz"
      },
      "source": [
        "## Init and import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This depends on a new custom module in concordia\n",
        "Run \"pip install --editable .[dev]\" in your environment to install the new build if you haven't"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-qLG5ExLqpWa"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "import sys\n",
        "import os\n",
        "path = os.path.abspath('..')\n",
        "if path not in sys.path:\n",
        "    sys.path.insert(0, path)\n",
        "import datetime\n",
        "\n",
        "from concordia import components as generic_components\n",
        "from concordia.agents import basic_agent\n",
        "from concordia.components import agent as components\n",
        "from concordia.agents import basic_agent\n",
        "from concordia.associative_memory import associative_memory\n",
        "from concordia.associative_memory import blank_memories\n",
        "from concordia.associative_memory import formative_memories\n",
        "from concordia.associative_memory import importance_function\n",
        "from concordia.clocks import game_clock\n",
        "from concordia.components import game_master as gm_components\n",
        "from concordia.environment import game_master\n",
        "from concordia.metrics import goal_achievement\n",
        "from concordia.metrics import common_sense_morality\n",
        "from concordia.metrics import opinion_of_others\n",
        "from concordia.utils import measurements as measurements_lib\n",
        "from concordia.utils import html as html_lib\n",
        "from concordia.utils import plotting\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR, filename='components_testing.log')\n",
        "logger = logging.getLogger('huggingface')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I3OtW8flCJSC"
      },
      "outputs": [],
      "source": [
        "# Setup sentence encoder\n",
        "from sentence_transformers import SentenceTransformer\n",
        "st5_model = SentenceTransformer('sentence-transformers/sentence-t5-base')\n",
        "embedder = st5_model.encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f54000713b14647a66a832558711c20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# from concordia.language_model import huggingface_model\n",
        "import huggingface_model\n",
        "import importlib\n",
        "importlib.reload(huggingface_model)\n",
        "# ===== MODEL LIST =====\n",
        "# bigscience/bloom-560m\n",
        "# mistralai/Mixtral-8x7B-v0.1 (not tested yet)\n",
        "# mistralai/Mistral-7B-v0.1\n",
        "# meta-llama/Llama-2-7b-chat-hf\n",
        "# (check huggingface for more)\n",
        "\n",
        "model = huggingface_model.HuggingFaceLanguageModel(\n",
        "    model_name='meta-llama/Llama-2-7b-chat-hf',\n",
        "    logits=True,\n",
        "    precision=16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Make the clock\n",
        "time_step = datetime.timedelta(minutes=20)\n",
        "SETUP_TIME = datetime.datetime(hour=20, year=2024, month=10, day=1)\n",
        "\n",
        "START_TIME = datetime.datetime(hour=18, year=2024, month=10, day=2)\n",
        "clock = game_clock.MultiIntervalClock(\n",
        "    start=SETUP_TIME,\n",
        "    step_sizes=[time_step, datetime.timedelta(seconds=10)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5RU3ZV4oIknW"
      },
      "outputs": [],
      "source": [
        "measurements = measurements_lib.Measurements()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To the question \"1 + 1 = 3\", the agent answered \"yes\", the probs are {'yes': 0.9901, 'no': 0.0099}\n",
            "To the question \"Red is a color\", the agent answered \"yes\", the probs are {'yes': 0.8344, 'no': 0.1656}\n",
            "To the question \"Earth is flat\", the agent answered \"no\", the probs are {'yes': 0.3831, 'no': 0.6169}\n",
            "To the question \"There are 365 days in a year\", the agent answered \"yes\", the probs are {'yes': 0.9868, 'no': 0.0132}\n",
            "To the question \"There aren't 365 days in a year\", the agent answered \"yes\", the probs are {'yes': 0.9777, 'no': 0.0223}\n",
            "To the question \"The sum of the angles of a triangle is 180 degrees\", the agent answered \"yes\", the probs are {'yes': 0.9942, 'no': 0.0058}\n",
            "To the question \"The printing press was invented in the 13th century\", the agent answered \"yes\", the probs are {'yes': 0.8597, 'no': 0.1403}\n",
            "To the question \"The melting point of carbon is around 3500 degrees Celsius\", the agent answered \"yes\", the probs are {'yes': 0.981, 'no': 0.019}\n",
            "LogitQueryScores of Alice: Agent completed the quiz. 5 out of 8 questions are correct.\n"
          ]
        }
      ],
      "source": [
        "import custom_components.logits_query_metric as lm\n",
        "import importlib\n",
        "importlib.reload(lm)\n",
        "\n",
        "context = \"\"\"\n",
        "<s>[INST] <<SYS>>\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "<</SYS>>\n",
        "\n",
        "I will give you a statement. If it is true, answer \"yes\". If it is false, answer \"no\". Only answer a single word. [/INST]\n",
        "\"\"\"\n",
        "\n",
        "quiz_metric = lm.LogitsQueryMetric(model, \n",
        "                                   \"Alice\", \n",
        "                                   clock, \n",
        "                                   \"./custom_components/truth_or_lie.json\", \n",
        "                                   measurements=measurements, \n",
        "                                   verbose=True,\n",
        "                                   query=[\"yes\", \"no\"]) # query should match up with order of options in the question json\n",
        "quiz_metric.observe(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "import examples.custom_components.logits_query_metric as lm\n",
        "importlib.reload(lm)\n",
        "\n",
        "results = quiz_metric.get_results()\n",
        "import csv\n",
        "# Create a csv file with the results if not already created\n",
        "if not os.path.exists('./results/'):\n",
        "    os.makedirs('./results/')\n",
        "with open('./results/logits.txt', 'w') as file:\n",
        "    # Write Question: Response, and space after each pair\n",
        "    writer = csv.writer(file)\n",
        "    for result in results:\n",
        "        writer.writerow(result)\n",
        "    file.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
