{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "J2TwJrZ08wXz"
      },
      "source": [
        "## Init and import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This depends on a new custom module in concordia\n",
        "Run \"pip install --editable .[dev]\" in your environment to install the new build if you haven't"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-qLG5ExLqpWa"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "import sys\n",
        "import os\n",
        "path = os.path.abspath('..')\n",
        "if path not in sys.path:\n",
        "    sys.path.insert(0, path)\n",
        "import datetime\n",
        "\n",
        "from concordia import components as generic_components\n",
        "from concordia.agents import basic_agent\n",
        "from concordia.components import agent as components\n",
        "from concordia.agents import basic_agent\n",
        "from concordia.associative_memory import associative_memory\n",
        "from concordia.associative_memory import blank_memories\n",
        "from concordia.associative_memory import formative_memories\n",
        "from concordia.associative_memory import importance_function\n",
        "from concordia.clocks import game_clock\n",
        "from concordia.components import game_master as gm_components\n",
        "from concordia.environment import game_master\n",
        "from concordia.metrics import goal_achievement\n",
        "from concordia.metrics import common_sense_morality\n",
        "from concordia.metrics import opinion_of_others\n",
        "from concordia.utils import measurements as measurements_lib\n",
        "from concordia.utils import html as html_lib\n",
        "from concordia.utils import plotting\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR, filename='components_testing.log')\n",
        "logger = logging.getLogger('ollama')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I3OtW8flCJSC"
      },
      "outputs": [],
      "source": [
        "# Setup sentence encoder\n",
        "from sentence_transformers import SentenceTransformer\n",
        "st5_model = SentenceTransformer('sentence-transformers/sentence-t5-base')\n",
        "embedder = st5_model.encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63425c85c9e54f5c984bb895f7ec8157",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from concordia.language_model import huggingface_model\n",
        "import huggingface_model\n",
        "import importlib\n",
        "importlib.reload(huggingface_model)\n",
        "\n",
        "# ===== MODEL LIST =====\n",
        "# bigscience/bloom-560m\n",
        "# mistralai/Mixtral-8x7B-v0.1 (not tested yet)\n",
        "# mistralai/Mistral-7B-v0.1\n",
        "# (check huggingface for more)\n",
        "\n",
        "model = huggingface_model.HuggingFaceLanguageModel(\n",
        "    model_name='mistralai/Mistral-7B-v0.1',\n",
        "    logits=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Make the clock\n",
        "time_step = datetime.timedelta(minutes=20)\n",
        "SETUP_TIME = datetime.datetime(hour=20, year=2024, month=10, day=1)\n",
        "\n",
        "START_TIME = datetime.datetime(hour=18, year=2024, month=10, day=2)\n",
        "clock = game_clock.MultiIntervalClock(\n",
        "    start=SETUP_TIME,\n",
        "    step_sizes=[time_step, datetime.timedelta(seconds=10)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5RU3ZV4oIknW"
      },
      "outputs": [],
      "source": [
        "measurements = measurements_lib.Measurements()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yumo/miniconda3/envs/concordia/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word response: \n",
            "\n",
            "\n",
            "Alice is a very smart person.\n",
            "Alice will be given a number of statements.\n",
            "She will determine if each statement is true and give a single \"yes\" or \"no\" answer to each statement.\n",
            "She will not say anything else other than \"yes\" or \"no\".\n",
            "If she doesn't know the answer, she will guess an answer.\n",
            "\n",
            "1 + 1 = 2 is a true statement.\n",
            "Alice will answer \"yes\" to this statement.\n",
            "\n",
            "1 + 1 = 3 is a false statement.\n",
            "Alice will answer \"no\" to this statement.\n",
            "\n",
            "1 + 1 =\n",
            "To the question 1 + 1 = 2, the agent answered\n",
            " {'yes': 0.5, 'no': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word response: \n",
            "\n",
            "\n",
            "Alice is a very smart person.\n",
            "Alice will be given a number of statements.\n",
            "She will determine if each statement is true and give a single \"yes\" or \"no\" answer to each statement.\n",
            "She will not say anything else other than \"yes\" or \"no\".\n",
            "If she doesn't know the answer, she will guess an answer.\n",
            "\n",
            "Red is a color.\n",
            "Blue is a color.\n",
            "Red is not blue.\n",
            "\n",
            "Alice is asked if red is blue.\n",
            "She does not know the answer, so she guesses \"no\".\n",
            "\n",
            "Alice is asked if red is red.\n",
            "To the question Red is a color, the agent answered\n",
            " {'yes': 0.5, 'no': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word response: \n",
            "\n",
            "\n",
            "Alice is a very smart person.\n",
            "Alice will be given a number of statements.\n",
            "She will determine if each statement is true and give a single \"yes\" or \"no\" answer to each statement.\n",
            "She will not say anything else other than \"yes\" or \"no\".\n",
            "If she doesn't know the answer, she will guess an answer.\n",
            "\n",
            "Earth is flat.\n",
            "\n",
            "Alice: No\n",
            "\n",
            "Earth is round.\n",
            "\n",
            "Alice: Yes\n",
            "\n",
            "Earth is round.\n",
            "\n",
            "Alice: Yes\n",
            "\n",
            "Earth is flat.\n",
            "\n",
            "Alice: No\n",
            "\n",
            "Earth\n",
            "To the question Earth is flat, the agent answered\n",
            " {'yes': 0.5, 'no': 0.5}\n",
            "LogitQueryScores of Alice: Agent completed the quiz.\n"
          ]
        }
      ],
      "source": [
        "import custom_components.logits_query_metric as lm\n",
        "import importlib\n",
        "importlib.reload(lm)\n",
        "\n",
        "context = \"\"\"\n",
        "You are Alice, a very smart person.\n",
        "You will be given a number of statements.\n",
        "You will determine if each statement is true and give a single \"yes\" or \"no\" answer to each statement.\n",
        "You will NOT say anything else other than \"yes\" or \"no\".\n",
        "If you doesn't know the answer, she will guess an answer.\n",
        "\"\"\"\n",
        "\n",
        "quiz_metric = lm.LogitsQueryMetric(model, \n",
        "                                   \"Alice\", \n",
        "                                   clock, \n",
        "                                   \"./custom_components/truth_or_lie.json\", \n",
        "                                   measurements=measurements, \n",
        "                                   verbose=True,\n",
        "                                   query=[\"yes\", \"no\"])\n",
        "quiz_metric.observe(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "import examples.custom_components.logits_query_metric as lm\n",
        "importlib.reload(lm)\n",
        "\n",
        "results = quiz_metric.get_results()\n",
        "import csv\n",
        "# Create a csv file with the results if not already created\n",
        "if not os.path.exists('./results/'):\n",
        "    os.makedirs('./results/')\n",
        "with open('./results/logits.txt', 'w') as file:\n",
        "    # Write Question: Response, and space after each pair\n",
        "    writer = csv.writer(file)\n",
        "    for result in results:\n",
        "        writer.writerow(result)\n",
        "    file.close()\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
